# -*- coding: utf-8 -*-
"""harshit

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ucrLLpaGaz9ys06FsLecU6wdz3c-ab0b
"""

import streamlit as st
import pandas as pd # Still useful for other data ops, but not for detector training data
import re # Still useful for general text manipulation if needed
# NLTK imports are removed as preprocessing is handled by the pre-trained model
# from nltk.corpus import stopwords
# from nltk.stem import WordNetLemmatizer
# from nltk.tokenize import word_tokenize

from sklearn.feature_extraction.text import TfidfVectorizer # No longer needed for detector
from sklearn.linear_model import LogisticRegression # No longer needed for detector

from transformers import pipeline, GPT2Tokenizer, GPT2LMHeadModel # Keep for generator
import torch
import os
import requests # Still needed for downloading generator model if not cached


# --- Configuration for Data URLs (No longer needed for detector data) ---
# TRUE_NEWS_URL = "https://drive.google.com/uc?export=download&id=1t1M4CXDfifk1EP7K3_e6vh9I-yslfLTn"
# FAKE_NEWS_URL = "https://drive.google.com/uc?export=download&id=1tam_5hrqy1CcZ12mMGlBTw7y-dt3NjWj"

# --- NLTK Data Initialization (Completely removed as pre-trained model handles it) ---
# No nltk.download() or path patching needed in app.py

# --- Text Preprocessing Function (Simplified/Removed for detector as pre-trained model handles it) ---
# This function is no longer needed for the detector path, but keeping a simplified version
# for potential general text cleaning if needed elsewhere or for future features.
@st.cache_data
def preprocess_text_general(text):
    """General text cleaning (not used by pre-trained detector)."""
    # If NLTK is needed for other parts, ensure it's installed via Dockerfile/requirements.txt
    # For now, this function is just a placeholder if needed.
    text = str(text).lower()
    text = re.sub(r'[^a-z\s]', '', text)
    return text # Simplified, as full NLP is done by pre-trained model

# --- Data Download Function (No longer needed for detector's training data) ---
# @st.cache_resource
# def download_data_files(true_url, fake_url):
#    ... (removed)


# --- NEW: Load Pre-trained Detector Pipeline ---
@st.cache_resource
def load_pretrained_detector_pipeline():
    """Loads a pre-trained fake news detection model from Hugging Face."""
    st.spinner("Loading pre-trained Fake News Detector model... This may take a moment.")
    try:
        # Using a common pre-trained model for fake news detection
        # This model outputs labels like 'LABEL_0' (real) and 'LABEL_1' (fake)
        # You might need to verify what LABEL_0/1 means from the model card on Hugging Face
        detector_pipeline = pipeline("text-classification", model="mrm8488/distilroberta-finetuned-fake-news-detection")
        st.success("Pre-trained Fake News Detector loaded!")
        return detector_pipeline
    except Exception as e:
        st.error(f"Error loading pre-trained detector model: {e}")
        st.warning("Ensure you have internet access for the initial download of the detector model.")
        return None

# --- Original Generator Pipeline (remains the same) ---
@st.cache_resource
def load_generator_pipeline():
    """Loads the pre-trained GPT-2 text generation pipeline."""
    st.spinner("Loading GPT-2 generator model... This may take a moment (first time download).")
    try:
        device = "cpu" # Force CPU for Streamlit Cloud deployment
        generator_pipeline = pipeline(
            'text-generation',
            model='gpt2',
            tokenizer='gpt2',
            device=0 if torch.cuda.is_available() else -1
        )
        st.success(f"GPT-2 generator loaded! Running on: {device.upper()}")
        return generator_pipeline
    except requests.exceptions.RequestException as e:
        st.error(f"Network error downloading GPT-2 model: {e}")
        st.warning("This often happens due to temporary network issues or rate limiting from Hugging Face.")
        st.warning("Please try refreshing the app or deploying again later.")
        return None
    except Exception as e:
        st.error(f"Error loading generator model: {e}")
        st.warning("Ensure you have internet access for the initial download of GPT-2.")
        return None

# --- Main Streamlit App Layout and Theming ---
st.set_page_config(
    page_title="Fake News AI",
    page_icon="üïµÔ∏è",
    layout="wide",
    initial_sidebar_state="collapsed"
)

st.title("üïµÔ∏è Fake News Detector & News Generator ‚úçÔ∏è")
st.markdown("""
    <style>
    .stApp {
        background-color: #0e1117;
        color: #e0e0e0;
    }
    .stButton>button {
        background-color: #4CAF50;
        color: white;
        border-radius: 12px;
        border: none;
        padding: 10px 24px;
        text-align: center;
        text-decoration: none;
        display: inline-block;
        font-size: 16px;
        margin: 4px 2px;
        cursor: pointer;
        transition-duration: 0.4s;
        box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2), 0 6px 20px 0 rgba(0,0,0,0.19);
    }
    .stButton>button:hover {
        background-color: #45a049;
        box-shadow: 0 12px 16px 0 rgba(0,0,0,0.24), 0 17px 50px 0 rgba(0,0,0,0.19);
    }
    .stTextArea textarea {
        background-color: #1a1c20;
        color: #e0e0e0;
        border-radius: 8px;
        border: 1px solid #333;
    }
    .stTextInput input {
        background-color: #1a1c20;
        color: #e0e0e0;
        border-radius: 8px;
        border: 1px solid #333;
    }
    .stSlider .stSliderHandle {
        background-color: #4CAF50;
    }
    .stSlider .stSliderTrack {
        background-color: #333;
    }
    .stAlert {
        border-radius: 8px;
    }
    .stAlert.error {
        background-color: #ff4d4f;
        color: white;
    }
    .stAlert.success {
        background-color: #52c41a;
        color: white;
    }
    .stAlert.warning {
        background-color: #faad14;
        color: white;
    }
    a {
        color: #1890ff;
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    </style>
    """, unsafe_allow_html=True)


st.markdown("""
    Welcome to the Fake News AI prototype! This application demonstrates two key aspects of combating misinformation:
    identifying fake news and understanding how synthetic text can be generated.
""")

# --- Load Models on App Startup ---
# Load the pre-trained detector pipeline
detector_pipeline = load_pretrained_detector_pipeline()

# Load the generator pipeline
generator_pipeline = load_generator_pipeline()

# --- Fake News Detector Section ---
st.header("üîç Fake News Detector")
st.markdown("Enter any news text below to check if it's likely real or fake.")

detector_input = st.text_area("News Article Text:", height=200, key="detector_input")

if st.button("Detect News", key="detect_button"):
    if detector_input and detector_pipeline:
        with st.spinner("Analyzing news text..."):
            # The pre-trained pipeline handles all preprocessing
            result = detector_pipeline(detector_input)[0]
            label = result['label'] # e.g., 'LABEL_0', 'LABEL_1'
            score = result['score'] # Confidence score

            # Map labels to human-readable format based on the model's output
            # You might need to adjust this mapping based on the specific model's output
            if label == 'LABEL_0': # Assuming LABEL_0 is REAL, LABEL_1 is FAKE
                st.success(f"‚úÖ This news is likely **REAL.** (Confidence: {score:.2f})")
            elif label == 'LABEL_1':
                st.error(f"üö® This news is likely **FAKE!** (Confidence: {score:.2f})")
            else:
                st.info(f"Prediction: {label} (Confidence: {score:.2f}) - Please verify model's label mapping.")
    elif not detector_input:
        st.warning("Please enter some text to detect.")
    else:
        st.warning("Detector is not ready. Please check for errors above.")

st.markdown("---")

# --- News Generator Section ---
st.header("‚úçÔ∏è News Generator")
st.markdown("Enter a prompt, and the AI will generate text for you. This demonstrates general text generation capabilities.")

generator_prompt = st.text_input("Enter a prompt (e.g., 'Breaking news from the capital:', 'Scientists discover...'):", key="generator_prompt")
max_gen_length = st.slider("Maximum generated text length:", 50, 500, 150, key="max_length_slider")

if st.button("Generate Text", key="generate_button"):
    if generator_prompt and generator_pipeline:
        with st.spinner("Generating text..."):
            generated_text_output = generator_pipeline(
                generator_prompt,
                max_length=max_gen_length,
                num_return_sequences=1,
                do_sample=True,
                temperature=0.7,
                top_k=50,
                top_p=0.95
            )[0]['generated_text']
        st.text_area("Generated Text:", generated_text_output, height=250, key="generated_output")
    elif not generator_prompt:
        st.warning("Please enter a prompt to generate text.")
    else:
        st.warning("Generator is not ready. Please check for errors above.")

st.markdown("---")
st.caption("Project by Harshit Dubey")
st.caption("Note: The generator uses a base GPT-2 model. For specialized 'fake news' generation, further fine-tuning would be required.")

# --- Connect with Me Section ---
st.markdown("<br>", unsafe_allow_html=True)
st.subheader("Connect with Harshit Dubey")

col1, col2, col3 = st.columns([1,1,1])

with col1:
    st.markdown(
        """
        <a href="https://www.instagram.com/harshitdubey00?igsh=OTJuOGNvbWI4c2Fj" target="_blank" style="text-decoration: none;">
            <img src="https://upload.wikimedia.org/wikipedia/commons/a/a5/Instagram_icon.png" alt="Instagram" width="30" height="30" style="vertical-align: middle; margin-right: 5px;">
            <span style="font-size: 18px; color: #E1306C;">Instagram</span>
        </a>
        """,
        unsafe_allow_html=True
    )

with col2:
    st.markdown(
        """
        <a href="https://github.com/harshitdubey0" target="_blank" style="text-decoration: none;">
            <img src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg" alt="GitHub" width="30" height="30" style="vertical-align: middle; margin-right: 5px;">
            <span style="font-size: 18px; color: #6e5494;">GitHub</span>
        </a>
        """,
        unsafe_allow_html=True
    )

with col3:
    st.markdown(
        """
        <a href="mailto:harshitdubey11578@gmail.com" style="text-decoration: none;">
            <img src="https://upload.wikimedia.org/wikipedia/commons/4/4e/Gmail_Icon.png" alt="Email" width="30" height="30" style="vertical-align: middle; margin-right: 5px;">
            <span style="font-size: 18px; color: #DB4437;">Email</span>
        </a>
        """,
        unsafe_allow_html=True
    )