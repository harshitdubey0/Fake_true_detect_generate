# -*- coding: utf-8 -*-
"""Fake News Detector & Generator Web App (app.py) with Data Download Links

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rP1d3LVHgq1VioZcHI5W9ndV7xvAhZ1c
"""

import streamlit as st
import pandas as pd
import re
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from transformers import pipeline, GPT2Tokenizer, GPT2LMHeadModel
import torch
import os
import requests # This import is now essential for downloading files

# --- Configuration for Data URLs ---
# These are the direct download links for your True.csv and Fake.csv files from Google Drive.
TRUE_NEWS_URL = "https://drive.google.com/uc?export=download&id=1t1M4CXDfifk1EP7K3_e6vh9I-yslfLTn"
FAKE_NEWS_URL = "https://drive.google.com/uc?export=download&id=1tam_5hrqy1CcZ12mMGlBTw7y-dt3NjWj"

# --- NLTK Data Download (Run only if needed, Streamlit handles caching) ---
@st.cache_resource
def download_nltk_data():
    """Downloads necessary NLTK data packages."""
    try:
        nltk.download('punkt', quiet=True)
        nltk.download('stopwords', quiet=True)
        nltk.download('wordnet', quiet=True)
        nltk.download('punkt_tab', quiet=True)
        st.success("NLTK data downloaded successfully!")
    except Exception as e:
        st.error(f"Failed to download NLTK data: {e}")

download_nltk_data()

# --- Text Preprocessing Function (Cached for efficiency) ---
@st.cache_data
def preprocess_text(text):
    """Cleans and preprocesses text for the detector."""
    lemmatizer = WordNetLemmatizer()
    stop_words = set(stopwords.words('english'))

    text = str(text).lower()
    text = re.sub(r'[^a-z\s]', '', text) # Remove punctuation and numbers
    words = word_tokenize(text)
    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]
    return " ".join(words)

# --- Data Download Function (New) ---
@st.cache_resource
def download_data_files(true_url, fake_url):
    """Downloads True.csv and Fake.csv from specified URLs."""
    data_dir = "data_cache"
    os.makedirs(data_dir, exist_ok=True) # Create a directory to store downloaded files

    true_news_path = os.path.join(data_dir, "True.csv")
    fake_news_path = os.path.join(data_dir, "Fake.csv")

    # Download True.csv
    if not os.path.exists(true_news_path):
        st.spinner(f"Downloading True.csv from {true_url}...")
        try:
            r = requests.get(true_url, stream=True)
            r.raise_for_status() # Raise an exception for bad status codes (e.g., 404, 500)
            with open(true_news_path, 'wb') as f:
                for chunk in r.iter_content(chunk_size=8192):
                    f.write(chunk)
            st.success("True.csv downloaded!")
        except Exception as e:
            st.error(f"Failed to download True.csv: {e}")
            return None, None

    # Download Fake.csv
    if not os.path.exists(fake_news_path):
        st.spinner(f"Downloading Fake.csv from {fake_url}...")
        try:
            r = requests.get(fake_url, stream=True)
            r.raise_for_status() # Raise an exception for bad status codes
            with open(fake_news_path, 'wb') as f:
                for chunk in r.iter_content(chunk_size=8192):
                    f.write(chunk)
            st.success("Fake.csv downloaded!")
        except Exception as e:
            st.error(f"Failed to download Fake.csv: {e}")
            return None, None

    return true_news_path, fake_news_path

# --- Model Training and Loading (Cached for efficiency) ---
@st.cache_resource
def load_and_train_detector_model(true_news_path, fake_news_path):
    """Loads data, preprocesses, and trains the Fake News Detector."""
    st.spinner("Loading and training detector model... This may take a moment.")
    try:
        # Load data from downloaded paths
        true_news = pd.read_csv(true_news_path)
        fake_news = pd.read_csv(fake_news_path)

        # Add labels and combine
        true_news['label'] = 0
        fake_news['label'] = 1
        df = pd.concat([true_news, fake_news], ignore_index=True)
        df = df.sample(frac=1, random_state=42).reset_index(drop=True)
        df['full_text'] = df['title'].fillna('') + " " + df['text'].fillna('')

        # Preprocess text
        df['processed_text'] = df['full_text'].apply(preprocess_text)

        # Feature extraction (TF-IDF)
        vectorizer = TfidfVectorizer(max_features=5000)
        X = vectorizer.fit_transform(df['processed_text'])
        y = df['label']

        # Train model
        model = LogisticRegression(max_iter=1000)
        model.fit(X, y)

        st.success("Detector model loaded and trained!")
        return model, vectorizer
    except Exception as e:
        st.error(f"Error loading or training detector: {e}")
        return None, None

@st.cache_resource
def load_generator_pipeline():
    """Loads the pre-trained GPT-2 text generation pipeline."""
    st.spinner("Loading GPT-2 generator model... This may take a moment (first time download).")
    try:
        generator_pipeline = pipeline(
            'text-generation',
            model='gpt2',
            tokenizer='gpt2',
            device=0 if torch.cuda.is_available() else -1
        )
        st.success("GPT-2 generator loaded!")
        return generator_pipeline
    except Exception as e:
        st.error(f"Error loading generator model: {e}")
        st.warning("Ensure you have internet access for the initial download of GPT-2.")
        return None

# --- Main Streamlit App Layout ---
st.set_page_config(page_title="Fake News AI", page_icon="üïµÔ∏è", layout="centered")

st.title("üïµÔ∏è Fake News Detector & Generator")
st.markdown("""
    Welcome to the Fake News AI prototype! This application demonstrates two key aspects of combating misinformation:
    identifying fake news and understanding how synthetic text can be generated.
""")

# --- Data Download and Model Loading on App Startup ---
# These paths will be where the files are downloaded to in the Streamlit environment
true_news_file_path, fake_news_file_path = download_data_files(TRUE_NEWS_URL, FAKE_NEWS_URL)

detector_model, tfidf_vectorizer = None, None
if true_news_file_path and fake_news_file_path:
    detector_model, tfidf_vectorizer = load_and_train_detector_model(true_news_file_path, fake_news_file_path)
else:
    st.error("Could not download necessary data files. Detector will not function.")


generator_pipeline = load_generator_pipeline()

# --- Fake News Detector Section ---
st.header("üîç Fake News Detector")
st.markdown("Enter any news text below to check if it's likely real or fake.")

detector_input = st.text_area("News Article Text:", height=200, key="detector_input")

if st.button("Detect News", key="detect_button"):
    if detector_input and detector_model and tfidf_vectorizer:
        with st.spinner("Analyzing news text..."):
            processed_input = preprocess_text(detector_input)
            vectorized_input = tfidf_vectorizer.transform([processed_input])
            prediction = detector_model.predict(vectorized_input)[0]

            if prediction == 1:
                st.error("üö® This news is likely **FAKE!**")
            else:
                st.success("‚úÖ This news is likely **REAL.**")
    elif not detector_input:
        st.warning("Please enter some text to detect.")
    else:
        st.warning("Detector is not ready. Please check for errors above.")

st.markdown("---")

# --- Fake News Generator Section ---
st.header("‚úçÔ∏è Text Generator")
st.markdown("Enter a prompt, and the AI will generate text for you. This demonstrates general text generation capabilities.")

generator_prompt = st.text_input("Enter a prompt (e.g., 'Breaking news from the capital:', 'Scientists discover...'):", key="generator_prompt")
max_gen_length = st.slider("Maximum generated text length:", 50, 500, 150, key="max_length_slider")

if st.button("Generate Text", key="generate_button"):
    if generator_prompt and generator_pipeline:
        with st.spinner("Generating text..."):
            generated_text_output = generator_pipeline(
                generator_prompt,
                max_length=max_gen_length,
                num_return_sequences=1,
                do_sample=True,
                temperature=0.7,
                top_k=50,
                top_p=0.95
            )[0]['generated_text']
        st.text_area("Generated Text:", generated_text_output, height=250, key="generated_output")
    elif not generator_prompt:
        st.warning("Please enter a prompt to generate text.")
    else:
        st.warning("Generator is not ready. Please check for errors above.")

st.markdown("---")
st.caption("Project by Harshit Dubey | Guided by Gaurav Singh")
st.caption("Note: The generator uses a base GPT-2 model. For specialized 'fake news' generation, further fine-tuning would be required.")